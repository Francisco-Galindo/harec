# Compiler

<div align="center">
  <img src="https://cloudfront-us-east-1.images.arcpublishing.com/infobae/QLXAPU64VVD7DMR5ZF7VIEH4HQ.jpg" alt="Logo UNAM" width="200"/>
  <p> Universidad Nacional Autónoma de México </p>
  <p> Ingeniería en Computación </p>
  <p> Compiladores </p>
  <p> Hare Compiler </p>
  <p> Alumnos: </p>
  <p>320198388</p>
  <p>320051665</p>
  <p>320298608</p>
  <p>320244612</p>
  <p>320054336</p>
  <p> Grupo 5 </p>
  <p> Semestre 2025-2 </p>
  <p> México, CDMX. Junio 2025 </p>
</div>


## Introduction
In this project, we will develop a compiler and its corresponding parser using the Hare programming language, both as the implementation language and as the language to be compiled. The main focus will be on the design and implementation of the syntax and semantic analysis stages, which are essential components of any compiler.

Syntax analysis verifies the structural correctness of the source code according to the language's grammar. This involves constructing a parser capable of identifying valid program constructs and producing an intermediate representation, typically in the form of a syntax tree. For this stage, we develop a recursive descent parser by applying theoretical concepts.

Semantic analysis complements syntax analysis by checking that the code adheres to the language's rules beyond its form—ensuring, for example, that operations are applied to compatible types and that identifiers are properly declared. It also involves building a symbol table to store relevant information about program elements.

Creating a compiler is necessary for understanding how programming languages are processed and executed. By completing this project, we aim to produce a working compiler for Hare and gain practical knowledge of compiler construction techniques, particularly those related to parsing and semantic validation.

## Theorical Background
### What is a Compiler?
A compiler is a program that reads a program written in one language, the source language, and translates it into an equivalent program in another language, the target language. In essence, a compiler maps a source program into a semantically equivalent target program. This mapping process consists of two main parts: analysis and synthesis.

The analysis phase breaks the source program into its constituent components and assigns a grammatical structure to them. Based on this structure, it generates an intermediate representation of the source program. During this phase, the compiler also collects information about the program and stores it in a data structure known as the symbol table. This table, along with the intermediate representation, is passed to the synthesis phase.

The synthesis phase uses this intermediate representation and the symbol table to construct the corresponding target program. Compilation is typically organized as a sequence of phases, with each phase transforming the program representation in preparation for the next.

The first phase of a compiler is called lexical analysis or scanning. The lexical analyzer reads the stream of characters from the source program and groups them into meaningful sequences called lexemes. For each lexeme, it produces a corresponding token, which is then passed to the next phase, syntax analysis.

The second phase, known as syntax analysis or parsing, uses the tokens generated by the lexical analyzer to build a tree-like intermediate structure that reflects the grammatical organization of the token stream. A common form of this structure is the syntax tree, where each internal node represents an operation, and the children represent its operands. The syntax tree visually illustrates the order in which operations are to be executed.

The semantic analyzer takes the syntax tree and symbol table to ensure the source program complies with the language's semantic rules. It also gathers type information, storing it in either the syntax tree or the symbol table for later use during intermediate code generation. A key task during semantic analysis is type checking, where the compiler verifies that each operator is used with correctly typed operands.

As the compiler translates the source program into target code, it may generate one or more intermediate representations, which can take various forms. After completing syntax and semantic analysis, many compilers produce a low-level, machine-like intermediate representation, essentially a program for an abstract machine. This is often expressed as a sequence of three-address code instructions.

The code generation phase takes this intermediate representation and translates it into the target language. If the target is machine code, the compiler allocates registers or memory locations for each variable and translates the intermediate instructions into machine instructions that perform the equivalent tasks.

An important function of a compiler is to record the variable names used in the source program and track information about each one’s attributes. This is managed through the symbol table, a data structure that contains an entry for each variable, with fields for its associated attributes.

For large programs, compilation is often done in parts. The resulting relocatable machine code may need to be linked with other object files and libraries to form a complete executable. The linker resolves references to external memory addresses where code in one file refers to locations in another. Finally, the loader places the fully linked executable into memory, ready for execution.

### About the sintax analysis
Parsing is a fundamental process in the field of computer science, especially within the domains of compilers, interpreters, and language processing systems. It involves analyzing a sequence of tokens or symbols based on the rules defined by a formal grammar, with the purpose of constructing a syntactic structure, often in the form of a parse tree or abstract syntax tree. Parsing techniques are generally classified into top-down and bottom-up methods. Recursive descent parsing belongs to the former category and is one of the most widely understood and implemented parsing strategies due to its straightforward and modular approach.

Recursive descent parsing operates by associating each non-terminal in a grammar with a corresponding function in the parser. These functions call one another in a recursive manner to recognize structures in the input, hence the term "recursive descent". As the input string is processed from left to right, the parser attempts to apply production rules that correspond to the structure of the grammar, descending through the hierarchy of rules until it either accepts the input or fails due to a mismatch.

This method is particularly suitable for grammars that conform to the LL(1) class, meaning they can be parsed from left to right with Leftmost derivation using one lookahead token. However, for recursive descent to function correctly, the grammar must be free of left recursion. Left-recursive productions, which allow a non-terminal to appear as the leftmost symbol in one of its own derivations, can lead to infinite recursion and must therefore be transformed before the grammar can be parsed using this technique. Similarly, ambiguous or poorly factored grammars may require rewriting to ensure that decisions can be made deterministically based on the next token in the input stream.

Despite its advantages, recursive descent parsing does have limitations. Its reliance on grammars that are LL(1) restricts its applicability to a subset of possible languages. Moreover, maintaining a recursive descent parser for a large and complex grammar can become cumbersome and error-prone, particularly when compared to automated parser generators or more powerful bottom-up parsing techniques. Nevertheless, for many use cases, particularly those involving smaller grammars or where control and transparency are valued over generality, recursive descent remains an effective and reliable method.

### About the semantic analysis


### Compiler

## Development
### Parser
The parser is a fundamental component of the compiler, responsible for analyzing the syntactic structure of the source code and transforming it into an internal representation that the rest of the compiler can work with. In this project, the parser was built specifically to process code written in the Hare programming language.

The development of the parser began with the formal definition of the grammar rules that describe valid Hare constructs. These rules, grounded in theoretical models such as context-free grammars, guided the structure of the parser and ensured that the syntax recognized was consistent with the language specification.

We based on the grammar that was already described in Hare's language especification, we didn't have any trouble since this grammar is LL(1).  This makes our parser design a lot simpler, which was a deliberate goal of the language design. The parser was designed to process a sequence of tokens —produced by a lexer— and validate whether those tokens form valid syntactic structures like variable declarations, expressions, or function definitions. During this stage, the parser also constructs an abstract syntax tree (AST), which represents the hierarchical structure of the program in a form that can be traversed and analyzed by later compilation stages.

Key to the development was the identification and separation of concerns. Each syntactic construct was handled by a specific part of the parser, allowing for modularity and clarity. The design aimed to closely follow the grammar rules, making the parser easier to extend and debug.

By the end of this phase, the parser was capable of transforming raw Hare source code into a structured and meaningful representation, ready for semantic analysis and code generation. This work highlights the importance of applying formal language theory and grammar design in the practical construction of programming tools.

### Compiler construction

#### Linker
In this project, we did not develop a custom linker; we relied on the one included with GCC. Since the compiler targets the RISC-V architecture, the generated assembly code was tailored to match the specific structure of our test cases.

### Test inputs



## Results



## Conclusion
This project demonstrates the practical application of theoretical concepts in compiler construction, highlighting the structured progression from abstract syntax rules to concrete code generation. By implementing a compiler and parser for the Hare programming language, written in Hare itself, we reinforced foundational principles such as formal grammars, lexical analysis, syntax analysis, and semantic analysis.

Instead of relying on external libraries during the syntax analysis phase, we chose to build a recursive descent parser based on theoretical concepts covered in class and supported by bibliographic references. The semantic analysis phase was implemented through a symbol table that validates identifiers by checking their presence within a defined scope. This approach aligns with the theoretical model of symbol resolution and scope management, illustrating how simple data structures can effectively enforce semantic rules.

Furthermore, by targeting the RISC-V architecture for code generation, the project required precise translation from high-level constructs to a register-based, low-level instruction set. This provided a concrete application of the theoretical mapping between intermediate representations and target machine code.

Our compiler, although basic in comparison to a Java compiler, supports block-structured code such as if statements, for loops, and functions, allowing simple programs to be parsed, compiled, and executed successfully.

Overall, the project exemplifies how theoretical knowledge, such as grammar definitions, parsing strategies, scope rules, and target architecture modeling, can be systematically applied to develop a working compiler. The results validate the importance of a solid theoretical foundation for solving complex systems-level programming problems.
## Sources

Aho, A. V., Lam, M. S., Sethi, R., & Ullman, J. D. (2013). Compilers: Principles, Techniques, and Tools (2da ed.). Pearson.

Hare specification. (s. f.). Harelang. https://harelang.org/specification
